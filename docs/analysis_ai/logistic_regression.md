[线性回归模型](https://github.com/likuli/data-analysis-learning/blob/main/docs/analysis_ai/linear_regression.md)是一种回归模型，它用于对连续变量进行预测，如预测收入范围、客户价值等。如果要对离散变量进行预测，则要使用分类模型。分类模型与回归模型的区别在于其预测的变量不是连续的，而是离散的一些类别，例如，最常见的二分类模型可以预测一个人是否会违约、客户是否会流失、肿瘤是良性还是恶性等。本文要学习的逻辑回归模型虽然名字中有“回归”二字，但其在**本质上却是分类模型**。

## 逻辑回归模型的数学原理

既然逻辑回归模型是分类模型，为什么名字里会含有“回归”二字呢？这是因为其算法原理同样涉及线性回归模型中的线性回归方程：

$y=k_0+k_1x_1+k_2x_2+k_3x_3+...$

上面这个方程是用于预测连续变量的，其取值范围为（-∞，＋∞），而逻辑回归模型是用于预测类别的，例如，用逻辑回归模型预测某物品是属于A类还是B类，在本质上预测的是该物品属于A类或B类的概率，而概率的取值范围是0～1，因此不能直接用线性回归方程来预测概率，那么如何把一个取值范围是（-∞，＋∞）的回归方程变为取值范围是（0，1）的内容呢？

这就需要用到下图所示的Sigmoid函数，它可将取值范围为（-∞，＋∞）的数转换到（0，1）之间。下面我们来看一下Sigmoid函数的推导过程，$y$是之前提到的线性回归方程，取值范围是（-∞，＋∞），那么指数函数 $e^y$ 的取值范围是（0，＋∞），再做一次变换， $\frac{e^y}{1+e^y}$ 的取值范围就变成（0，1），然后分子分母同除以 $e^y$ ，就得到了Sigmoid函数：

$$
\begin{cases}
\quad\quad\quad\quad\quad\quad\quad\quad 将(-\infty, +\infty)转变为（0,1） \\
y=  k_0+k_1x_1+k_2x_2+k_3x_3+... \longrightarrow e^y \longrightarrow \frac{e^y}{1+e^y} \longrightarrow \frac{1}{1+e^{-y}}\\
\quad\quad\quad\quad\quad\downarrow \quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\downarrow \quad\quad\quad\quad\downarrow \quad\quad\quad\quad\downarrow\\
\quad\quad\quad(-\infty, +\infty) \quad\quad\quad\quad\quad\quad\quad (0, +\infty) \quad(0, 1) \quad\quad(0, 1) \\
\end{cases}
$$

总结来说，逻辑回归模型本质就是将线性回归模型通过Sigmoid函数进行了一个非线性转换，得到一个介于0～1之间的概率值，对于二分类问题（分类0和1）而言，其预测分类为1（或者说二分类中数值较大的分类）的概率可以用如下所示的公式计算：

$$
P = \frac{1}{1+e^{-(k_0+k_1x_1+k_2x_2+k_3x_3+...)}}
$$

因为概率和为1，则分类为0（或者说二分类中数值较小的分类）的概率为1-P。

逻辑回归模型的本质就是预测属于各个分类的概率，有了概率之后，就可以进行分类了。对于二分类问题来说，例如在预测客户是否会违约的模型中，如果预测违约的概率P为70%，则不违约的概率为30%，违约概率大于不违约概率，此时就可以认为该客户会违约。对于多分类问题来说，逻辑回归模型会预测属于各个分类的概率（各个概率之和为1），然后根据哪个概率最大，判定属于哪个分类。

了解了逻辑回归模型的基本原理后，在实际模型搭建中，就是要找到合适的系数ki和截距项k0，使预测的概率较为准确，在数学中使用极大似然估计法来确定合适的系数ki和截距项k0，从而得到相应的概率。在Python中，已经有相应的库将数学方法整合好了，通过调用库中的模块就能建立逻辑回归模型，从而预测概率并进行分类。
